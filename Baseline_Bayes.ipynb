{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import csv\n",
    "import time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy import interp\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, auc, roc_curve, roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUE_LABEL = [\n",
    "    'Transient', \n",
    "    'False Alarm', \n",
    "    'Won\\'t Fix', \n",
    "    'Unable To Reproduce', \n",
    "    'Customer Error',\n",
    "    'Won\\'t fix',\n",
    "    'By Design',\n",
    "]\n",
    "TRUE_LABEL = list(set([i.upper() for i in TRUE_LABEL]))\n",
    "\n",
    "def getClass(x):\n",
    "    if x.upper() in TRUE_LABEL:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(project_name, model_name, pred, probs, test_labels, fit_time, predict_time, model):\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(test_labels, probs, pos_label=0)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    lw = 2\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(model_name)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "                       \n",
    "    csv_write = csv.writer(open('learning-bayes.csv','a',newline=''), dialect='excel')\n",
    "    csv_write.writerow([\n",
    "        project_name, model_name, \n",
    "        roc_auc,\n",
    "        precision_score(test_labels, pred, average= 'macro'), \n",
    "        recall_score(test_labels, pred, average= 'macro'),\n",
    "        f1_score(test_labels, pred, average= 'macro'),\n",
    "        accuracy_score(test_labels, pred), \n",
    "        fit_time, predict_time\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_do(project_name):\n",
    "    print('====')\n",
    "    print(project_name)\n",
    "    print('====')   \n",
    "    vectorizer = CountVectorizer(min_df=1)\n",
    "  \n",
    "    ROOTPATH = 'PATH'\n",
    "    samples = pickle.load(open(ROOTPATH + project_name +  '_train_title_summary.pkl','rb'))   \n",
    "    samples['tokenized'] = samples['tokenized'].apply(lambda x: (' ').join(x))\n",
    "    all_tokenized = samples['tokenized']\n",
    "    all_labels = samples['Label']\n",
    "    all_labels_binary = [getClass(x) for x in all_labels]\n",
    "    print('load train set')\n",
    "    \n",
    "    samples = pickle.load(open(ROOTPATH + project_name +  '_test_title_summary.pkl','rb'))\n",
    "    samples['tokenized'] = samples['tokenized'].apply(lambda x: (' ').join(x))\n",
    "    test_tokenized = samples['tokenized']\n",
    "    test_labels = samples['Label']\n",
    "    test_labels_binary = [getClass(x) for x in test_labels]\n",
    "    print('load test set')\n",
    "    \n",
    "    train_matrix = vectorizer.fit_transform(all_tokenized)\n",
    "    print('train_matrix', train_matrix.shape)\n",
    "    \n",
    "    train_matrix_next = np.zeros(train_matrix.shape)\n",
    "    train_matrix_next[0] = train_matrix[0].toarray().flatten()/2\n",
    "    for i in range(train_matrix_next.shape[0]-1):\n",
    "        train_matrix_next[i+1] =  (train_matrix_next[i] + train_matrix[i+1].toarray().flatten())/2\n",
    "    print('train_matrix', train_matrix_next.shape)\n",
    "    \n",
    "    vectorizer_test = CountVectorizer(vocabulary = vectorizer.vocabulary_);\n",
    "    test_matrix = vectorizer_test.fit_transform(test_tokenized)\n",
    "    \n",
    "    test_matrix_next = np.zeros(test_matrix.shape)\n",
    "    test_matrix_next[0] = test_matrix[0].toarray().flatten()/2\n",
    "    for i in range(test_matrix_next.shape[0]-1):\n",
    "        test_matrix_next[i+1] =  (test_matrix_next[i] + test_matrix[i+1].toarray().flatten())/2\n",
    "    print('test_matrix', test_matrix_next.shape)\n",
    "    \n",
    "    print('bayes fit...', test_matrix.shape)\n",
    "    start = time.clock()\n",
    "    gnb = GaussianNB().fit(train_matrix_next, all_labels_binary)\n",
    "    end = time.clock()\n",
    "    \n",
    "    print('bayes predict...')\n",
    "    start_p = time.clock()\n",
    "    pred = gnb.predict(test_matrix_next)\n",
    "\n",
    "    end_p = time.clock()\n",
    "    pred_proba = gnb.predict_proba(test_matrix_next)\n",
    "    pred_proba = [x[0] for x in pred_proba]\n",
    "    \n",
    "    print('bayes save...')\n",
    "    save_result(project_name, 'Bayes', pred, pred_proba, test_labels_binary, end-start, end_p-start_p, gnb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
